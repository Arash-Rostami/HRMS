Compiled in Feb 2025 – Arash Rostami:@0.670497:0.957116:0.879211:0.957116:0.879211:0.947638:0.670497:0.947638:0.007145:0.007064:0.010710:0.007037:0.003083:0.003150:0.006675:0.007037:0.003029:0.003083:0.007078:0.003029:0.005938:0.006675:0.007037:0.003110:0.006836:0.006756:0.006836:0.006756:0.003111:0.006652:0.003124:0.007761:0.004437:0.006421:0.005241:0.007064:0.003029:0.006943:0.007064:0.005134:0.004330:0.006541:0.010710:0.003083
   :@0.500067:0.957116:0.495235:0.957116:0.495235:0.947638:0.500067:0.947638:0.003029:-0.010891:0.003029
Part 5: Core Principles of :@0.128536:0.106965:0.407610:0.106965:0.407610:0.085561:0.128536:0.085561:0.013808:0.012634:0.010027:0.009135:0.006481:0.013526:0.006434:0.006481:0.014653:0.014348:0.009276:0.012704:0.006481:0.014419:0.009511:0.006669:0.014207:0.011342:0.006669:0.014560:0.006669:0.012704:0.010333:0.006481:0.014043:0.008994:0.006481
Effective Prompting :@0.128536:0.132549:0.355806:0.132549:0.355806:0.111145:0.128536:0.111145:0.012493:0.008994:0.008994:0.012704:0.011272:0.009135:0.006740:0.012493:0.012704:0.006481:0.014419:0.009346:0.014348:0.021511:0.014560:0.009135:0.006716:0.014207:0.014536:0.006481
 :@0.355909:0.132549:0.362391:0.132549:0.362391:0.111145:0.355909:0.111145:0.006481
 :@0.163811:0.167707:0.170292:0.167707:0.170292:0.146303:0.163811:0.146303:0.006481
5.1:@0.128536:0.199781:0.154640:0.199781:0.154640:0.181409:0.128536:0.181409:0.010865:0.004374:0.010865
 Rules:@0.154640:0.199781:0.211039:0.199781:0.211039:0.181409:0.154640:0.181409:0.005543:0.013163:0.012195:0.005725:0.010905:0.008869
 :@0.211080:0.199781:0.216643:0.199781:0.216643:0.181409:0.211080:0.181409:0.005563
Clarity and Specificity::@0.128536:0.231281:0.339844:0.231281:0.339844:0.212909:0.128536:0.212909:0.012578:0.005725:0.010905:0.008023:0.005725:0.007902:0.010845:0.005563:0.010885:0.012094:0.012397:0.005563:0.011308:0.012497:0.010905:0.009675:0.005725:0.007720:0.005725:0.009675:0.005725:0.007841:0.010845:0.005463
 :@0.339884:0.231281:0.345448:0.231281:0.345448:0.212909:0.339884:0.212909:0.005563
•:@0.158772:0.262287:0.166514:0.262287:0.166514:0.247755:0.158772:0.247755:0.007742
 :@0.166532:0.262215:0.171211:0.262215:0.171211:0.248945:0.166532:0.248945:0.004679
Avoid Ambiguity: Using :@0.189008:0.262709:0.403097:0.262709:0.403097:0.244337:0.189008:0.244337:0.012598:0.009655:0.011812:0.004878:0.011873:0.005523:0.013001:0.017355:0.011852:0.004878:0.011873:0.011409:0.004818:0.006833:0.009756:0.004374:0.005523:0.013848:0.008547:0.004878:0.011409:0.011873:0.005523
precise language and :@0.189008:0.284659:0.384271:0.284659:0.384271:0.266287:0.189008:0.266287:0.011852:0.007075:0.010542:0.009313:0.004878:0.008547:0.010542:0.005523:0.004878:0.010260:0.011308:0.011873:0.011409:0.010260:0.011873:0.010603:0.005523:0.010260:0.011409:0.011812:0.005523
defining terms clearly.:@0.189008:0.306609:0.384492:0.306609:0.384492:0.288236:0.189008:0.288236:0.011873:0.010583:0.006309:0.004878:0.011409:0.004818:0.011409:0.011873:0.005523:0.006833:0.010603:0.007015:0.017275:0.008547:0.005523:0.009313:0.004878:0.010542:0.010260:0.007015:0.004878:0.009756:0.004374
 :@0.384533:0.306609:0.390056:0.306609:0.390056:0.288236:0.384533:0.288236:0.005523
•:@0.158772:0.337686:0.166514:0.337686:0.166514:0.323154:0.158772:0.323154:0.007742
 :@0.166532:0.337614:0.171211:0.337614:0.171211:0.324344:0.166532:0.324344:0.004679
Be Direct: Getting straight to the point and avoiding long introductions.:@0.189008:0.338108:0.823853:0.338108:0.823853:0.319736:0.189008:0.319736:0.011550:0.010603:0.005523:0.014130:0.004878:0.007015:0.010542:0.009313:0.006833:0.004374:0.005422:0.013828:0.010542:0.006833:0.006874:0.004878:0.011409:0.011873:0.005523:0.008547:0.006833:0.007015:0.010260:0.004818:0.011873:0.011409:0.006833:0.005523:0.006874:0.011812:0.005523:0.006833:0.011308:0.010542:0.005523:0.011933:0.011812:0.004818:0.011409:0.006833:0.005523:0.010260:0.011409:0.011812:0.005657:0.010260:0.009655:0.011812:0.004878:0.011873:0.004878:0.011349:0.011873:0.005523:0.004878:0.011812:0.011409:0.011873:0.005523:0.004878:0.011409:0.006833:0.007015:0.011812:0.011873:0.011409:0.009313:0.006833:0.004797:0.011812:0.011409:0.008547:0.004374
 :@0.823927:0.338108:0.829450:0.338108:0.829450:0.319736:0.823927:0.319736:0.005523
•:@0.158772:0.369114:0.166514:0.369114:0.166514:0.354582:0.158772:0.354582:0.007742
 :@0.166532:0.369042:0.171211:0.369042:0.171211:0.355772:0.166532:0.355772:0.004679
Focus on a Single Task: Breaking down complex requests into smaller, :@0.189008:0.369536:0.810153:0.369536:0.810153:0.351164:0.189008:0.351164:0.009837:0.011812:0.009313:0.011409:0.008547:0.005523:0.011812:0.011409:0.005523:0.010260:0.005523:0.010703:0.004878:0.011349:0.011873:0.004878:0.010542:0.005523:0.008305:0.010260:0.008547:0.010018:0.004414:0.005523:0.011590:0.007015:0.010542:0.010260:0.010018:0.004797:0.011409:0.011873:0.005523:0.011873:0.011812:0.014614:0.011409:0.005523:0.009313:0.011752:0.017355:0.011852:0.004939:0.010542:0.009292:0.005523:0.007015:0.010542:0.011873:0.011409:0.010542:0.008547:0.006833:0.008446:0.005523:0.004878:0.011409:0.006833:0.011812:0.005523:0.008547:0.017355:0.010260:0.004878:0.004797:0.010542:0.007075:0.004374:0.005523
focused prompts. Encouraging the model to think step-by-step to solve :@0.189008:0.391486:0.830841:0.391486:0.830841:0.373114:0.189008:0.373114:0.006309:0.011812:0.009313:0.011409:0.008547:0.010542:0.011873:0.005563:0.011792:0.007015:0.011732:0.017355:0.011852:0.006833:0.008587:0.004374:0.005523:0.010200:0.011349:0.009313:0.011812:0.011409:0.007015:0.010320:0.011873:0.004878:0.011409:0.011873:0.005523:0.006753:0.011409:0.010542:0.005523:0.017355:0.011812:0.011873:0.010583:0.004878:0.005523:0.006733:0.011812:0.005523:0.006833:0.011409:0.004878:0.011409:0.009917:0.005523:0.008547:0.006874:0.010542:0.012101:0.008063:0.011893:0.009776:0.008063:0.008547:0.006773:0.010542:0.011852:0.005523:0.006753:0.011812:0.005523:0.008547:0.011812:0.004878:0.009655:0.010542:0.005523
complex problems. Rather than providing the entire script, please present it :@0.189008:0.413507:0.863952:0.413507:0.863952:0.395135:0.189008:0.395135:0.009313:0.011752:0.017355:0.011852:0.004878:0.010542:0.009252:0.005563:0.011852:0.007015:0.011812:0.011852:0.004878:0.010542:0.017355:0.008547:0.004354:0.005543:0.012054:0.010260:0.006833:0.011409:0.010542:0.007015:0.005523:0.006894:0.011409:0.010260:0.011409:0.005422:0.011792:0.007015:0.011812:0.009655:0.004878:0.011873:0.004878:0.011409:0.011873:0.005523:0.006833:0.011409:0.010542:0.005563:0.010542:0.011409:0.006833:0.004878:0.006954:0.010542:0.005523:0.008607:0.009313:0.007015:0.004737:0.011852:0.006874:0.004374:0.005523:0.011852:0.004878:0.010542:0.010260:0.008547:0.010542:0.005523:0.011852:0.007015:0.010542:0.008587:0.010542:0.011409:0.006773:0.005523:0.004878:0.006833:0.005523
in different small segments (a paragraph) for a clearer and more precise :@0.189008:0.435457:0.830888:0.435457:0.830888:0.417085:0.189008:0.417085:0.004878:0.011409:0.005523:0.011873:0.004878:0.006309:0.006309:0.010583:0.007015:0.010542:0.011409:0.006833:0.005422:0.008547:0.017355:0.010260:0.004878:0.004818:0.005523:0.008547:0.010603:0.011873:0.017355:0.010542:0.011409:0.006833:0.008547:0.005584:0.006141:0.010260:0.005523:0.011852:0.010260:0.006954:0.010260:0.011873:0.007075:0.010179:0.011852:0.011449:0.006047:0.005543:0.006309:0.011812:0.007015:0.005523:0.010260:0.005523:0.009313:0.004878:0.010542:0.010260:0.007015:0.010542:0.007015:0.005523:0.010260:0.011349:0.011873:0.005523:0.017355:0.011812:0.007015:0.010603:0.005523:0.011852:0.006914:0.010542:0.009313:0.004878:0.008547:0.010542:0.005523
output:@0.189008:0.457407:0.249157:0.457407:0.249157:0.439035:0.189008:0.439035:0.011812:0.011409:0.006833:0.011852:0.011409:0.006833
.:@0.249177:0.457407:0.253551:0.457407:0.253551:0.439035:0.249177:0.439035:0.004374
 :@0.253511:0.457407:0.259034:0.457407:0.259034:0.439035:0.253511:0.439035:0.005523
Context and Background::@0.128536:0.488835:0.369334:0.488835:0.369334:0.470463:0.128536:0.470463:0.012578:0.012316:0.012195:0.007761:0.010905:0.011127:0.007841:0.005563:0.010845:0.012195:0.012477:0.005563:0.012921:0.010845:0.009675:0.010986:0.012477:0.007881:0.012316:0.012195:0.012195:0.012477:0.005463
 :@0.369314:0.488835:0.374877:0.488835:0.374877:0.470463:0.369314:0.470463:0.005563
•:@0.158772:0.519936:0.166514:0.519936:0.166514:0.505404:0.158772:0.505404:0.007742
 :@0.166532:0.519864:0.171211:0.519864:0.171211:0.506594:0.166532:0.506594:0.004679
Providing Sufficient Context: Setting the scene and giving the model the :@0.189008:0.520358:0.834664:0.520358:0.834664:0.501986:0.189008:0.501986:0.011288:0.007015:0.011812:0.009655:0.004878:0.011873:0.004878:0.011409:0.011873:0.005523:0.010703:0.011409:0.006309:0.006309:0.004878:0.009313:0.004797:0.010542:0.011409:0.006833:0.005563:0.012477:0.011812:0.011409:0.006833:0.010542:0.009252:0.006894:0.004374:0.005523:0.010703:0.010542:0.006833:0.006833:0.004777:0.011409:0.011873:0.005523:0.006833:0.011409:0.010583:0.005523:0.008547:0.009313:0.010542:0.011328:0.010542:0.005523:0.010320:0.011409:0.011873:0.005523:0.011873:0.004878:0.009655:0.004878:0.011268:0.011873:0.005523:0.006874:0.011409:0.010542:0.005523:0.017355:0.011812:0.011792:0.010542:0.004878:0.005523:0.006833:0.011409:0.010542:0.005523
necessary information. This could include role, scenario, background :@0.189008:0.542308:0.799973:0.542308:0.799973:0.523936:0.189008:0.523936:0.011409:0.010542:0.009313:0.010542:0.008547:0.008547:0.010320:0.007015:0.009756:0.005523:0.004878:0.011328:0.006309:0.011812:0.007055:0.017355:0.010260:0.006833:0.004878:0.011812:0.011349:0.004374:0.005523:0.010562:0.011409:0.004818:0.008547:0.005523:0.009313:0.011812:0.011409:0.004797:0.011973:0.005523:0.004878:0.011409:0.009232:0.004878:0.011409:0.011873:0.010542:0.005523:0.007015:0.011812:0.004959:0.010542:0.004374:0.005523:0.008547:0.009313:0.010542:0.011409:0.010260:0.007075:0.004878:0.011752:0.004374:0.005523:0.011852:0.010260:0.009313:0.010018:0.011873:0.007015:0.011812:0.011409:0.011409:0.011873:0.005523
information, etc.:@0.189008:0.564258:0.333878:0.564258:0.333878:0.545886:0.189008:0.545886:0.004878:0.011409:0.006309:0.011812:0.007015:0.017355:0.010260:0.006833:0.004878:0.011812:0.011349:0.004374:0.005523:0.010542:0.006833:0.009313:0.004374
 :@0.333837:0.564258:0.339360:0.564258:0.339360:0.545886:0.333837:0.545886:0.005523
•:@0.158772:0.595264:0.166514:0.595264:0.166514:0.580732:0.158772:0.580732:0.007742
 :@0.166532:0.595192:0.171211:0.595192:0.171211:0.581922:0.166532:0.581922:0.004679
Establishing Persona/Role: Instructing the model to adopt a specific persona :@0.189008:0.595686:0.869536:0.595686:0.869536:0.577314:0.189008:0.577314:0.010200:0.008547:0.006833:0.010260:0.011913:0.004878:0.004797:0.008547:0.011409:0.004878:0.011409:0.011873:0.005584:0.010583:0.010482:0.007015:0.008587:0.011812:0.011409:0.010260:0.007740:0.011490:0.011812:0.004818:0.010542:0.004374:0.005523:0.005362:0.011409:0.008547:0.006833:0.007015:0.011409:0.009313:0.006833:0.004878:0.011409:0.011873:0.005523:0.006833:0.011409:0.010542:0.005523:0.017355:0.011812:0.011873:0.010603:0.004878:0.005523:0.006833:0.011812:0.005523:0.010260:0.011873:0.011732:0.011852:0.006874:0.005523:0.010260:0.005563:0.008466:0.011852:0.010603:0.009313:0.004797:0.006309:0.004878:0.009313:0.005523:0.011852:0.010583:0.007015:0.008587:0.011812:0.011409:0.010260:0.005523
or role (e.g., \Act as a marketing expert\).:@0.189008:0.617707:0.552866:0.617707:0.552866:0.599335:0.189008:0.599335:0.011812:0.007015:0.005523:0.007075:0.011812:0.004818:0.010542:0.005523:0.006087:0.010542:0.004374:0.011873:0.004273:0.004374:0.005523:0.007841:0.013001:0.009313:0.006833:0.005523:0.010260:0.008547:0.005563:0.010260:0.005463:0.017355:0.010260:0.007015:0.010018:0.010542:0.006833:0.004878:0.011409:0.011873:0.005463:0.010542:0.009292:0.011852:0.010542:0.007015:0.006833:0.007902:0.006087:0.004374
 :@0.552879:0.617707:0.558402:0.617707:0.558402:0.599335:0.552879:0.599335:0.005523
•:@0.158772:0.648713:0.166514:0.648713:0.166514:0.634181:0.158772:0.634181:0.007742
 :@0.166532:0.648641:0.171211:0.648641:0.171211:0.635371:0.166532:0.635371:0.004679
Referencing Previous Turns (in conversational models): Maintaining :@0.189008:0.649135:0.789431:0.649135:0.789431:0.630763:0.189008:0.630763:0.011490:0.010542:0.006370:0.010482:0.007015:0.010603:0.011409:0.009252:0.004878:0.011409:0.011873:0.005523:0.011288:0.007015:0.010542:0.009655:0.004818:0.011812:0.011409:0.008547:0.005523:0.010562:0.011409:0.007015:0.011409:0.008547:0.005563:0.006087:0.004797:0.011409:0.005523:0.009313:0.011752:0.011409:0.009655:0.010542:0.007075:0.008547:0.010260:0.006874:0.004878:0.011651:0.011409:0.010260:0.004878:0.005523:0.017355:0.011752:0.011873:0.010583:0.004878:0.008547:0.006027:0.004374:0.005523:0.018101:0.010260:0.004878:0.011409:0.006833:0.010260:0.004878:0.011409:0.004878:0.011409:0.011873:0.005523
coherence in multi-turn conversations.:@0.189008:0.671085:0.530108:0.671085:0.530108:0.652713:0.189008:0.652713:0.009313:0.011752:0.011409:0.010542:0.007015:0.010623:0.011409:0.009252:0.010542:0.005523:0.004878:0.011409:0.005523:0.017355:0.011409:0.004818:0.006833:0.004878:0.008063:0.006833:0.011409:0.007015:0.011409:0.005523:0.009313:0.011812:0.011409:0.009655:0.010542:0.007055:0.008547:0.010260:0.006833:0.004797:0.011812:0.011409:0.008547:0.004374
 :@0.530202:0.671085:0.535725:0.671085:0.535725:0.652713:0.530202:0.652713:0.005523
Instruction Type and Framing::@0.128536:0.702585:0.412894:0.702585:0.412894:0.684212:0.128536:0.684212:0.006390:0.012195:0.008869:0.007841:0.008023:0.012195:0.009675:0.007841:0.005765:0.012316:0.012195:0.005563:0.010845:0.010845:0.012497:0.010905:0.005563:0.010845:0.012195:0.012518:0.005563:0.010482:0.008023:0.010845:0.018464:0.005765:0.012195:0.012477:0.005463
 :@0.412887:0.702585:0.418451:0.702585:0.418451:0.684212:0.412887:0.684212:0.005563
•:@0.158772:0.733590:0.166514:0.733590:0.166514:0.719059:0.158772:0.719059:0.007742
 :@0.166532:0.733519:0.171211:0.733519:0.171211:0.720249:0.166532:0.720249:0.004679
Action Verbs and Keywords: Using strong action verbs (e.g., \Summarize:@0.189008:0.734013:0.844379:0.734013:0.844379:0.715640:0.189008:0.715640:0.013001:0.009313:0.006833:0.004878:0.011732:0.011409:0.005523:0.011288:0.010542:0.007015:0.011852:0.008547:0.005563:0.010260:0.011409:0.011873:0.005523:0.011429:0.010482:0.009675:0.014574:0.011812:0.007015:0.011933:0.008547:0.004374:0.005523:0.013848:0.008547:0.004818:0.011409:0.011873:0.005523:0.008547:0.006874:0.007015:0.011812:0.011409:0.011873:0.005523:0.010260:0.009232:0.006833:0.004878:0.011812:0.011349:0.005523:0.009655:0.010603:0.007015:0.011913:0.008466:0.005523:0.006087:0.010542:0.004374:0.011873:0.004374:0.004293:0.005523:0.007902:0.010703:0.011349:0.017416:0.017355:0.010260:0.007015:0.004878:0.009111:0.010542:0.004374:0.007821:0.005523
\Analyze:@0.189008:0.755963:0.455990:0.755963:0.455990:0.737590:0.189008:0.737590:0.007902:0.013001:0.011409:0.010260:0.004797:0.009756:0.009111:0.010542:0.004374:0.007841:0.005624:0.007902:0.010200:0.009292:0.011852:0.004878:0.010260:0.004878:0.011409:0.004293:0.007902:0.005523:0.007841:0.012578:0.007015:0.010603:0.010260:0.006833:0.010542:0.007841:0.006087:0.004374
 :@0.456024:0.755963:0.461547:0.755963:0.461547:0.737590:0.456024:0.737590:0.005523
•:@0.158772:0.787040:0.166514:0.787040:0.166514:0.772508:0.158772:0.772508:0.007742
 :@0.166532:0.786968:0.171211:0.786968:0.171211:0.773698:0.166532:0.773698:0.004679
Instruction Formats: Exploring different instruction formats like questions, :@0.189008:0.787462:0.845549:0.787462:0.845549:0.769090:0.189008:0.769090:0.005362:0.011409:0.008547:0.006833:0.007015:0.011409:0.009313:0.006833:0.004878:0.011752:0.011409:0.005523:0.009837:0.011812:0.007015:0.017355:0.010260:0.006894:0.008547:0.004374:0.005523:0.010200:0.009151:0.011852:0.004878:0.011812:0.007015:0.004878:0.011409:0.011873:0.005523:0.011873:0.004878:0.006309:0.006309:0.010542:0.007015:0.010603:0.011409:0.006733:0.005523:0.004878:0.011409:0.008547:0.006833:0.007015:0.011328:0.009313:0.006833:0.004818:0.011812:0.011409:0.005523:0.006309:0.011812:0.007015:0.017355:0.010260:0.006874:0.008547:0.005523:0.004878:0.004878:0.009938:0.010542:0.005523:0.011933:0.011409:0.010542:0.008486:0.006833:0.004878:0.011812:0.011349:0.008547:0.004374:0.005523
commands, directives, requests.:@0.189008:0.809412:0.470463:0.809412:0.470463:0.791040:0.189008:0.791040:0.009313:0.011752:0.017355:0.017355:0.010260:0.011409:0.011873:0.008547:0.004414:0.005523:0.011873:0.004878:0.007015:0.010603:0.009313:0.006833:0.004818:0.009655:0.010583:0.008547:0.004374:0.005422:0.007015:0.010603:0.011873:0.011409:0.010542:0.008547:0.006833:0.008547:0.004374
 :@0.470436:0.809412:0.475959:0.809412:0.475959:0.791040:0.470436:0.791040:0.005523
•:@0.158772:0.840441:0.166514:0.840441:0.166514:0.825910:0.158772:0.825910:0.007742
 :@0.166532:0.840370:0.171211:0.840370:0.171211:0.827100:0.166532:0.827100:0.004679
Positive vs. Negative Framing: Understanding when to tell the model what to :@0.189008:0.840864:0.874575:0.840864:0.874575:0.822491:0.189008:0.822491:0.010583:0.011812:0.008547:0.004878:0.006833:0.004878:0.009655:0.010542:0.005523:0.009655:0.008587:0.004374:0.005402:0.015078:0.010603:0.011873:0.010200:0.006833:0.004878:0.009655:0.010542:0.005563:0.009776:0.007015:0.010260:0.017295:0.004878:0.011409:0.011873:0.004293:0.005523:0.013848:0.011409:0.011933:0.010542:0.007075:0.008547:0.006773:0.010260:0.011409:0.011873:0.004878:0.011409:0.011873:0.005523:0.014574:0.011409:0.010542:0.011409:0.005523:0.006894:0.011812:0.005523:0.006753:0.010542:0.004878:0.004878:0.005523:0.006833:0.011409:0.010542:0.005523:0.017355:0.011812:0.011873:0.010583:0.004878:0.005523:0.014574:0.011409:0.010260:0.006833:0.005563:0.006833:0.011812:0.005523
do vs. what not to do.:@0.189008:0.862814:0.382739:0.862814:0.382739:0.844441:0.189008:0.844441:0.011873:0.011812:0.005523:0.009655:0.008587:0.004374:0.005523:0.014574:0.011409:0.010260:0.006773:0.005523:0.011409:0.011812:0.006833:0.005523:0.006833:0.011812:0.005523:0.011913:0.011812:0.004374
 :@0.382719:0.862814:0.388242:0.862814:0.388242:0.844441:0.382719:0.844441:0.005523
Output Format and Constraints::@0.128536:0.894313:0.429443:0.894313:0.429443:0.875941:0.128536:0.875941:0.015279:0.012195:0.007841:0.012497:0.012195:0.007902:0.005563:0.010482:0.012316:0.008023:0.018464:0.010845:0.007841:0.005563:0.010845:0.012195:0.012538:0.005563:0.012578:0.012316:0.012195:0.008869:0.007841:0.008023:0.010905:0.005725:0.012195:0.007781:0.008869:0.005463
 :@0.429517:0.894313:0.435080:0.894313:0.435080:0.875941:0.429517:0.875941:0.005563